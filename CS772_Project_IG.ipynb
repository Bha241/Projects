{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZhnr-DZ5XKG"
      },
      "source": [
        "### Explainability using Integrated Gradients for Natural Language Processing\n",
        "(An amazing approach suggested in the paper https://arxiv.org/pdf/1703.01365.pdf,\n",
        "allows us to attribute importance to each feature input,\n",
        "regardless of model architecture)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwNOlKs6cQJZ",
        "outputId": "6ee11916-93a2-4d3f-8892-f70420339a28"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYhXl6S5YAG"
      },
      "source": [
        "# Import all the libraries\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import seaborn as sns\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.colors import Normalize, rgb2hex\n",
        "import pandas as pd\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "pd.set_option('display.max_colwidth', 150)\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhRBWj1r5i_b"
      },
      "source": [
        "# download the ag_news_subset dataset; https://www.tensorflow.org/datasets/catalog/ag_news_subset\n",
        "# split them into train/val/test, train:val = 90:10\n",
        "(raw_train_ds, raw_val_ds, raw_test_ds), info = tfds.load('IMDBReviews',\n",
        "                                                          split=['train[:90%]',\n",
        "                                                                 'train[-90%:]',\n",
        "                                                                 'test'],\n",
        "                                                          with_info=True)\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want to use 3 class  dataset\n",
        "\n",
        "# Filter the dataset to only include the first three classes\n",
        "raw_train_ds = raw_train_ds.filter(lambda x: x['label'] < 3)\n",
        "raw_val_ds = raw_val_ds.filter(lambda x: x['label'] < 3)\n",
        "raw_test_ds = raw_test_ds.filter(lambda x: x['label'] < 3)\n"
      ],
      "metadata": {
        "id": "pmnIrIUPaF05"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_test_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRlVsTIdfQUU",
        "outputId": "a09cb322-cbfe-4872-9d9d-b2f93985d6f9"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_FilterDataset element_spec={'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'text': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYf3zg1H5x3K",
        "outputId": "c870f9fd-a143-4ed3-c05b-48ac55bb1759"
      },
      "source": [
        "_LABEL_NAMES = info.features['label'].names\n",
        "print(_LABEL_NAMES)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'pos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN1cp84Q6G_I"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz_a66cr6DDW"
      },
      "source": [
        "# convert a sample of dataset into pandas df for easy viewing\n",
        "train_sample_df = \\\n",
        "    tfds.as_dataframe(raw_train_ds.shuffle(batch_size).take(5),\n",
        "                      ds_info=info)[[ 'label','text']]\n",
        "train_sample_df['topic'] = \\\n",
        "    train_sample_df['label'].apply(lambda x: _LABEL_NAMES[x])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2mmbYCUs6Ikt",
        "outputId": "7e4c7065-846d-4263-8a18-12e8c16539cb"
      },
      "source": [
        "(train_sample_df.head())"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  \\\n",
              "0      0   \n",
              "1      0   \n",
              "2      1   \n",
              "3      1   \n",
              "4      0   \n",
              "\n",
              "                                                                                                                                                    text  \\\n",
              "0  b'One of the weaker Carry On adventures sees Sid James as the head of a crime gang stealing contraceptive pills. The fourth of the series to be ho...   \n",
              "1  b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they alway...   \n",
              "2  b\"I first saw this as a child living in East London. The scars of Hitlers Luftwaffe were all too evident and the landscape of the movie was remini...   \n",
              "3  b'I was surprised at the low rating this film got from viewers. I saw it one late night on TV and it hit the spot - I actually think it was back i...   \n",
              "4  b\"The director Sidney J. Furie has created in Hollow Point a post-modern absurdist masterpiece that challenges and constantly surprises the audien...   \n",
              "\n",
              "  topic  \n",
              "0   neg  \n",
              "1   neg  \n",
              "2   pos  \n",
              "3   pos  \n",
              "4   neg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40cdfc1c-9489-4f29-8e59-9f733eacc5d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b'One of the weaker Carry On adventures sees Sid James as the head of a crime gang stealing contraceptive pills. The fourth of the series to be ho...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they alway...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>b\"I first saw this as a child living in East London. The scars of Hitlers Luftwaffe were all too evident and the landscape of the movie was remini...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>b'I was surprised at the low rating this film got from viewers. I saw it one late night on TV and it hit the spot - I actually think it was back i...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"The director Sidney J. Furie has created in Hollow Point a post-modern absurdist masterpiece that challenges and constantly surprises the audien...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40cdfc1c-9489-4f29-8e59-9f733eacc5d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40cdfc1c-9489-4f29-8e59-9f733eacc5d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40cdfc1c-9489-4f29-8e59-9f733eacc5d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2cee5bf8-149f-4d36-89b3-b0d3c4a210d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cee5bf8-149f-4d36-89b3-b0d3c4a210d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2cee5bf8-149f-4d36-89b3-b0d3c4a210d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(train_sample_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'\",\n          \"b\\\"The director Sidney J. Furie has created in Hollow Point a post-modern absurdist masterpiece that challenges and constantly surprises the audience. <br /><br />Sidney J. Furie dares to ask the question of what happens to the tired conventional traditionalist paradigms of 'plot' and 'characterisation' when you remove the crutches of 'motivation' and 'reason'. <br /><br />The result leads me to say that my opinion of him could not possibly get any higher.<br /><br />One and a half stars.<br /><br />P.S. Nothing in this movie makes any sense, the law enforcement agents are flat out unlikeable and the organised criminals are full on insane.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pos\",\n          \"neg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilfk5ngv7FdV"
      },
      "source": [
        "The Model's goal is to predict the topic (label) given the description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NHiKEzm7MjA"
      },
      "source": [
        "# Need to covert the dataset from dict to tuple;\n",
        "\n",
        "@tf.autograph.experimental.do_not_convert\n",
        "def convert_ds_to_tuple(sample):\n",
        "\n",
        "    \"\"\" the original dataset is of the form of a dict\n",
        "     {description: (), label: (), title: ()}\n",
        "\n",
        "      TF's model.fit() method required datasets to be of the form\n",
        "      A tf.data dataset that returns a tuple of (inputs, targets)\"\"\"\n",
        "\n",
        "    return sample['text'], sample['label']\n",
        "\n",
        "\n",
        "# converting all datasets from dicts to tuples\n",
        "raw_train_ds = raw_train_ds.map(convert_ds_to_tuple).batch(batch_size)\n",
        "raw_val_ds = raw_val_ds.map(convert_ds_to_tuple).batch(batch_size)\n",
        "raw_test_ds = raw_test_ds.map(convert_ds_to_tuple).batch(batch_size)\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UfjtG0G7ah3"
      },
      "source": [
        "# initiating model building;\n",
        "# build the tokenizer layer first\n",
        "vocab_size = 1000\n",
        "e_dim = 64\n",
        "n_classes = info.features['label'].num_classes\n",
        "pre_processing_layer = TextVectorization(max_tokens=vocab_size,\n",
        "                                         output_sequence_length=50,\n",
        "                                         name='Notes_preprocessing_layer')\n",
        "\n",
        "# fit the training set to the layer\n",
        "pre_processing_layer.adapt(raw_train_ds.map(lambda x, y: x))\n",
        "# store the vocab\n",
        "vocab = pre_processing_layer.get_vocabulary()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xm66qws7ec-",
        "outputId": "0f7c3105-a153-462e-ba03-06eb34a67314"
      },
      "source": [
        "# vectorize the text inputs\n",
        "\n",
        "@tf.autograph.experimental.do_not_convert\n",
        "def vectorize_text(text, label):\n",
        "\n",
        "    \"\"\" convert text to tokens \"\"\"\n",
        "\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return pre_processing_layer(text), label\n",
        "\n",
        "\n",
        "# print an example\n",
        "text_batch, label_batch = next(iter(raw_train_ds.shuffle(50)))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review: \", first_review)\n",
        "print(\"Label: \", _LABEL_NAMES[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review:  tf.Tensor(b\"The trailers for this film were better than the movie. What waste of talent and money. Wish I would've waited for this movie to come on DVD because at least I wouldn't be out $9. The movie totally misses the mark. What could have been a GREAT movie for all actors, turned out to be a B-movie at best. Movie moved VERY slow and just when I thought it was going somewhere, it almost did but then it didn't. In this day and age, we need unpredictable plot twists and closures in film, and this film offered neither. The whole thing about how everyone is a suspect is good, however, not sure if it was the way it was directed, the lighting, the delivery of lines, the writing or what, but nothing came from it. Lot of hype for nothing. I was VERY disappointed in this film, and I'm telling everyone NOT to see it. The cheesy saxophone music throughout made the film worse as well. And the ending had NOTHING to do with the rest of the film. What a disappointment.\", shape=(), dtype=string)\n",
            "Label:  neg\n",
            "Vectorized review (<tf.Tensor: shape=(1, 50), dtype=int64, numpy=\n",
            "array([[  2,   1,  16,  11,  20,  67, 124,  71,   2,  18,  49, 424,   5,\n",
            "        686,   3, 281, 621,  10,   1,   1,  16,  11,  18,   6, 209,  21,\n",
            "        290,  81,  31, 210,  10, 554,  28,  46,   1,   2,  18, 467,   1,\n",
            "          2, 989,  49,  95,  26,  75,   4,  86,  18,  16,  32]])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsKk2-Ua7nF1"
      },
      "source": [
        "# tokenize all datasets and prepare for training\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Fk15UU7s-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edad8ad8-4f4a-4f05-b673-9c05fc81fe51"
      },
      "source": [
        "# Build the model\n",
        "# lets build a simple Bi-directional LSTM model\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                              output_dim=e_dim,\n",
        "                              name='embedding',\n",
        "                              mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(n_classes, activation='softmax', name='probs')\n",
        "])\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHYfkASW7zPK",
        "outputId": "93fd5f0c-fea5-48eb-e77b-dded102ee9ea"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          64000     \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                24832     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " probs (Dense)               (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89906 (351.20 KB)\n",
            "Trainable params: 89906 (351.20 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc1_SeaK71yZ"
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQhl_Erg7322",
        "outputId": "8f99d6de-8a97-4b07-88ad-c5b60421ac68"
      },
      "source": [
        "# train the model; lets try for 5 epochs\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5, verbose=1)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "176/176 [==============================] - 65s 345ms/step - loss: 0.6048 - sparse_categorical_accuracy: 0.6510 - val_loss: 0.4983 - val_sparse_categorical_accuracy: 0.7569\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 43s 243ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.7496 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.7695\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 42s 241ms/step - loss: 0.4793 - sparse_categorical_accuracy: 0.7668 - val_loss: 0.4568 - val_sparse_categorical_accuracy: 0.7810\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 43s 244ms/step - loss: 0.4613 - sparse_categorical_accuracy: 0.7793 - val_loss: 0.4383 - val_sparse_categorical_accuracy: 0.7934\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 43s 243ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.4211 - val_sparse_categorical_accuracy: 0.8054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788169e91090>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gL1noNR77AG",
        "outputId": "df211396-dac9-4ad9-ff22-89419a96525e"
      },
      "source": [
        "# evaluate the model\n",
        "model.evaluate(test_ds, verbose=2)\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196/196 - 7s - loss: 0.5256 - sparse_categorical_accuracy: 0.7370 - 7s/epoch - 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.525570809841156, 0.7369599938392639]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfJxXXAG861c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d378ee0-4bc1-4ea6-f41e-b7136bd38255"
      },
      "source": [
        "# get predictions\n",
        "test_probs = model.predict(test_ds)\n",
        "test_preds = tf.argmax(test_probs, axis=1)\n",
        "test_labels = \\\n",
        "    test_ds.flat_map(lambda x, y:\n",
        "                     tf.data.Dataset.from_tensor_slices(y)).as_numpy_iterator()\n",
        "test_labels = tf.convert_to_tensor(list(test_labels), dtype=test_preds.dtype)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196/196 [==============================] - 7s 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "lZP5ODT18-R9",
        "outputId": "de0d0f13-cba5-4669-b86c-04eaa3ff7177"
      },
      "source": [
        "# build confusion matrix\n",
        "cm = tf.math.confusion_matrix(test_labels, test_preds)\n",
        "\n",
        "# plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=_LABEL_NAMES,\n",
        "            yticklabels=_LABEL_NAMES, cbar=False)\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS2Icgpp9I0t"
      },
      "source": [
        "### INTEGRATED GRADIENTS for understanding feature importance\n",
        "Refer to https://arxiv.org/pdf/1703.01365.pdf for all the details\n",
        "\n",
        "\n",
        "##### VERY IMPORTANT : in Tensorflow, gradients dont pass through Embedding layer; so will get the embedding layer out, and build the rest of the model as `new_model`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqoEde3c9JkW"
      },
      "source": [
        "embed_layer = model.get_layer('embedding')\n",
        "\n",
        "# build new model with all layers after embedding layer\n",
        "new_model = tf.keras.Sequential()\n",
        "for layer in model.layers[1:]:\n",
        "    new_model.add(layer)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBRZf47i9UKD"
      },
      "source": [
        "# take some test data\n",
        "sample_vectors = next(test_ds.take(1).as_numpy_iterator())[0]\n",
        "sample_texts = next(raw_test_ds.take(1).as_numpy_iterator())[0]\n",
        "sample_labels = next(test_ds.take(1).as_numpy_iterator())[1]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRJ-0x_Z_LFC"
      },
      "source": [
        "Run all the code below this line to visualize a different example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkzbuyhR9ZMx"
      },
      "source": [
        "# select a random index\n",
        "index = tf.cast(tf.random.uniform(shape=[1],\n",
        "                                  minval=sample_vectors.shape[0]),\n",
        "                dtype=tf.int8).numpy()[0]\n",
        "# generate a random sample\n",
        "sample_text = sample_texts[index]\n",
        "sample_vector = sample_vectors[index]\n",
        "sample_label = sample_labels[index]\n",
        "# get embeddings\n",
        "sample_embed = embed_layer(sample_vector)\n",
        "# Create a Baseline vector with zero embeddings\n",
        "baseline_embed = tf.zeros(shape=tf.shape(sample_embed))\n",
        "# get preds for sample\n",
        "sample_preds = model(sample_vectors)[index]\n",
        "# print the results with color codes\n",
        "words = [vocab[i] for i in sample_vector]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0pjECFx9c8Y"
      },
      "source": [
        "def interpolate_texts(baseline, text, m_steps):\n",
        "\n",
        "    \"\"\" Linearly interpolate the input vector\n",
        "    (embedding layer output of the sample vector)\"\"\"\n",
        "\n",
        "    # Generate m_steps intervals for integral_approximation() below.\n",
        "    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n",
        "    # text = tf.cast(text, tf.float32)\n",
        "    alphas_x = alphas[:, tf.newaxis, tf.newaxis]\n",
        "    delta = text - baseline\n",
        "    texts = baseline + alphas_x * delta\n",
        "    return texts"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlFqzib9kkS"
      },
      "source": [
        "n_steps = 50\n",
        "\n",
        "interpolated_texts = interpolate_texts(baseline_embed,\n",
        "                                       sample_embed,\n",
        "                                       n_steps)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtBuoviZ9laJ",
        "outputId": "f3022c05-4b04-4356-dda7-8069cd7b1e71"
      },
      "source": [
        "interpolated_texts.shape\n",
        "# (num_interpolations, seq_len, embed_dim)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([51, 50, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5RUD1w59wzx"
      },
      "source": [
        "def compute_gradients(t, target_class_idx):\n",
        "\n",
        "    \"\"\" compute the gradient wrt to embedding layer output \"\"\"\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(t)\n",
        "        probs = new_model(t)[:, target_class_idx]\n",
        "    grads = tape.gradient(probs, t)\n",
        "    return grads"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYJfK0Lh95Fj"
      },
      "source": [
        "target_label = sample_label\n",
        "# target_label = 2\n",
        "path_gradients = compute_gradients(interpolated_texts, target_label)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dnZEt8yhF691",
        "outputId": "7ddbc031-88b1-400c-fc5a-a6b2355f7817"
      },
      "source": [
        "path_gradients.shape\n",
        "# (num_interpolations, seq_len, embed_dim)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([51, 50, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLzbrqQZ99MV"
      },
      "source": [
        "# sum the grads of the interpolated vectors\n",
        "all_grads = tf.reduce_sum(path_gradients, axis=0) / n_steps\n",
        "# mulitply grads by (input - baseline); baseline is zero vectors\n",
        "x_grads = tf.math.multiply(all_grads, sample_embed)\n",
        "# sum all gradients across the embedding dimension\n",
        "igs = tf.reduce_sum(x_grads, axis=-1).numpy()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1GtO3ZmCjxz"
      },
      "source": [
        "# took the code for this cell block from\n",
        "#  https://docs.seldon.io/projects/alibi/en/stable/examples/integrated_gradients_imdb.html\n",
        "\n",
        "def  hlstr(string, color='white'):\n",
        "    \"\"\"\n",
        "    Return HTML markup highlighting text with the desired color.\n",
        "    \"\"\"\n",
        "    return f\"<mark style=background-color:{color}>{string} </mark>\"\n",
        "\n",
        "\n",
        "def colorize(attrs, cmap='PiYG'):\n",
        "    \"\"\"\n",
        "    Compute hex colors based on the attributions for a single instance.\n",
        "    Uses a diverging colorscale by default and normalizes and scales\n",
        "    the colormap so that colors are consistent with the attributions.\n",
        "    \"\"\"\n",
        "\n",
        "    cmap_bound = tf.reduce_max(tf.abs(attrs))\n",
        "    norm = Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
        "    cmap = mpl.cm.get_cmap(cmap)\n",
        "\n",
        "    # now compute hex values of colors\n",
        "    colors = list(map(lambda x: rgb2hex(cmap(norm(x))), attrs))\n",
        "    return colors"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJJOz5oILO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e0c453-0320-4a5a-a348-943a676bf204"
      },
      "source": [
        "colors = colorize(igs)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-116-ac2b22f3d3a9>:20: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = mpl.cm.get_cmap(cmap)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "0PfojEXN-gzw",
        "outputId": "6c6a4eda-a027-4193-cacb-43c7c7681710"
      },
      "source": [
        "# print the sample and predictions\n",
        "print(f\"Sample Text: {sample_text}\\n\")\n",
        "# print(f\"Sample Vector: {sample_vector}\")\n",
        "# print(f\"True Label: {_LABEL_NAMES[sample_label]}\")\n",
        "# print(f\"Predicted Label: \"\n",
        "#       f\"{_LABEL_NAMES[tf.argmax(sample_preds).numpy()]}\")\n",
        "print(\"Predictions : \")\n",
        "for index in tf.argsort(sample_preds,\n",
        "                        axis=-1, direction='DESCENDING').numpy():\n",
        "    print(f\"\\t{_LABEL_NAMES[index]} --> {sample_preds[index]*100:0.2f}%\")\n",
        "\n",
        "print(f\"\\nTrue Label: {_LABEL_NAMES[sample_label]}\")\n",
        "print(f\"\\nAttributions for Label: {_LABEL_NAMES[target_label]}\")\n",
        "print(f\"\\nTop 5 Important words: \"\n",
        "      f\"{[words[i] for i in tf.argsort(igs, -1, 'DESCENDING')[:5]]}\\n\")\n",
        "HTML(\"\".join(list(map(hlstr, words, colors))))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text: b\"This is another one of those movies I just knew I would hate, but it ended up not being as bad as one would expect.<br /><br />It has a lot of T&A in it and even the DVD menu is chocked full of women's breast. The first few scenes of the movie has a lot of sex and nudity and I was beginning to think there would be no story at all just exploiting nudity for the sake of making money off a popular prequel 8MM.<br /><br />As I continued to watch there was just more sex and nudity and main characters that I could care less about, but then the story started to unfold and I started to see a point to it all, and it was a tad better.<br /><br />It is about a man who's fianc\\xc3\\xa9 is the daughter of an Ambasador and they all have a promising future until nude photos of a menage a trois sex act shows up and blackmail is in the senders cards. The man and his fianc\\xc3\\xa9 must now get to the bottom of who sent the pics and how to shut them up.<br /><br />The movie first of all is nothing to do with part 1, it doesn't even have anything to do with 8MM's, its about a sex video though so I can see the similarities, as small as they may be.<br /><br />The acting is neither good, nor bad, its just nobodies playing parts anybody could do. The films production value is middle of the road and its pure drama yawn.<br /><br />I did enjoy going along for the ride getting to the bottom of the blackmailers motives. I was anticipating answers which is way more than I could say for the first one which I consider garbage. This movie has some nice twists too which are always welcomed.<br /><br />It's not great, and it is very slow started, but it does ultimately entertain. I wasn't on the edge of my seat and I won't rave to my friends that this is a must see, but hey if you watch a lot of movies and always seek something new, this might entertain you for 90 minutes.\"\n",
            "\n",
            "Predictions : \n",
            "\tneg --> 80.78%\n",
            "\tpos --> 19.22%\n",
            "\n",
            "True Label: neg\n",
            "\n",
            "Attributions for Label: neg\n",
            "\n",
            "Top 5 Important words: ['is', '[UNK]', 'this', '[UNK]', '[UNK]']\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark style=background-color:#98cc5f>this </mark><mark style=background-color:#276419>is </mark><mark style=background-color:#f6c9e3>another </mark><mark style=background-color:#c51d7e>one </mark><mark style=background-color:#eaf5d9>of </mark><mark style=background-color:#fce5f1>those </mark><mark style=background-color:#f4f7f0>movies </mark><mark style=background-color:#e9f5d8>i </mark><mark style=background-color:#d2ecb0>just </mark><mark style=background-color:#fce3f0>knew </mark><mark style=background-color:#f7f7f6>i </mark><mark style=background-color:#f7cbe4>would </mark><mark style=background-color:#fce3f0>hate </mark><mark style=background-color:#f8f4f6>but </mark><mark style=background-color:#f4f7f0>it </mark><mark style=background-color:#f4c1df>[UNK] </mark><mark style=background-color:#dbf0bf>up </mark><mark style=background-color:#fbe8f2>not </mark><mark style=background-color:#f8f2f5>being </mark><mark style=background-color:#f6c7e3>as </mark><mark style=background-color:#f7f7f7>bad </mark><mark style=background-color:#eff6e5>as </mark><mark style=background-color:#e89ac6>one </mark><mark style=background-color:#f7f7f7>would </mark><mark style=background-color:#f9eef4>[UNK] </mark><mark style=background-color:#f3bdde>br </mark><mark style=background-color:#f7f7f6>it </mark><mark style=background-color:#c72482>has </mark><mark style=background-color:#e181b5>a </mark><mark style=background-color:#f9f1f5>lot </mark><mark style=background-color:#fbd9ec>of </mark><mark style=background-color:#f6f7f5>[UNK] </mark><mark style=background-color:#f1b5d9>in </mark><mark style=background-color:#e897c4>it </mark><mark style=background-color:#f2badc>and </mark><mark style=background-color:#d2ecb0>even </mark><mark style=background-color:#f7f7f6>the </mark><mark style=background-color:#fbe6f1>dvd </mark><mark style=background-color:#7dba40>[UNK] </mark><mark style=background-color:#f5f7f2>is </mark><mark style=background-color:#f5f7f3>[UNK] </mark><mark style=background-color:#f9eef4>full </mark><mark style=background-color:#f3f6ed>of </mark><mark style=background-color:#d0ecad>[UNK] </mark><mark style=background-color:#bee490>[UNK] </mark><mark style=background-color:#eaf5d9>the </mark><mark style=background-color:#f2f6ec>first </mark><mark style=background-color:#f5c4e1>few </mark><mark style=background-color:#ebf6db>scenes </mark><mark style=background-color:#ebf6db>of </mark>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4vAOrbD_D-M"
      },
      "source": [
        "Importance of the words are highlighted. Greener the color, the higher positive attribution of that feature towards the prediction. Opposite for pink-colored words. As you can see, features such as 'olympic', 'champions`, 'league' are contributing the most towards predicting the sample as 'Sports'\n",
        "\n"
      ]
    }
  ]
}